{
    "20":{
        "note": "Continuous, Single agent, fixed graph",
        "discrete": true,
        "run" : "PPO",
        "stop_iters": 200,
        "n_agents": 1,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": true
    },
    "24":{
        "note": "Discrete, Single agent, fixed graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 1,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": true
    },
    "28":{
        "note": "Discrete, Multi agent, fixed graph, three rounds",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 3,
        "alpha": 1,
        "beta": 0
    },
    "25":{
        "note": "Discrete, multi agent, fixed graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": true
    },
    "30":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 246,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false
    },
    "31":{
        "note": "Discrete, single agent, fixed graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 1,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false
    },
    "32":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 500,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false
    },
    "33":{
        "note": "Discrete, single agent, fixed graph, longer run time, basic model",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 500,
        "n_agents": 1,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "basic_model": true
    },
    "34":{
        "note": "Discrete, multi agent, multi graph, basic model",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "basic_model": true
    },
    "35":{
        "note": "Discrete, multi agent, multi graph, pro-social, basic model",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false
    },
    "36":{
        "note": "Discrete, multi agent, multi graph, pro-social",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "seed": 246,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false
    },
    "37":{
        "note": "TODO: WRITE ME",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 1000,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 3,
        "alpha": 1,
        "beta": 1,
        "debug": false
    },
    "38":{
        "note": "TODO: WRITE ME",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 1000,
        "n_agents": 2,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false
    },
    "39":{
        "note": "Discrete, single agent, fixed graph, longer run time, basic model",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 500,
        "n_agents": 1,
        "seed": 123,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "basic_model": true
    },
    "40":{
        "note": "Discrete, multi agent, multi graph, pro-social, multiple samples",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 5,
        "scenario":"volunteers dilemma",
        "invert_actions": false,
        "full_information": false
    },
    "41":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 5,
        "scenario":"volunteers dilemma",
        "invert_actions": false,
        "full_information": false

    },
    "42":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "scenario":"only one can bailout"
    },
    "43":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "scenario":"not enough money together"
    },
    "44":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"not in default"
    },
    "45":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "46":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"both agents can rescue"
    },
    "47":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 1000,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "48":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"only agent 0 can rescue"
    },
    "49":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"only agent 1 can rescue"
    },
    "50":{
        "note": "Discrete, multi agent, multi graph, coordination game",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "51":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 1,
        "invert_actions": true,
        "full_information": false,
        "scenario":"coordination game"
    },
    "52":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"debug fixed coordination game"
    },
    "53":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 10,
        "invert_actions": false,
        "full_information": false,
        "scenario":"only agent 0 can rescue"
    },
    "54":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 10,
        "invert_actions": false,
        "full_information": false,
        "scenario":"merged only agent 0 can rescue and only agent 1 can rescue"
    },
    "55":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 1,
        "invert_actions": true,
        "full_information": true,
        "scenario":"coordination game"
    },
    "56":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": true,
        "full_information": false,
        "scenario":"coordination game"
    },
    "57":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.5,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "58":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.05,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "59":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.10,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "60":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.15,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "61":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.20,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "62":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.25,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "63":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.30,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "64":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.35,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "65":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.40,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "66":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.45,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "67":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.50,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "68":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.55,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "69":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.60,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "70":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.65,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "71":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.70,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "72":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.75,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "73":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.80,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "74":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.85,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "75":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.90,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "76":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.95,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "77":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"uniformly mixed"
    },
    "78":{
        "note": "Tournament",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game",
        "tournament_number": 1
    },
    "79":{
        "note": "Tournament",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game",
        "tournament_number": 2
    },
    "80":{
        "note": "Tournament",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game",
        "tournament_number": 3
    },
    "81":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "82":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.80,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "83":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.60,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "84":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.40,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "85":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.20,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "86":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "87":{
        "note": "Pooled training - need to be ran with trainer_4v4. Betas in [0.2,0.4,0.6,0.8] are pooled and sampled from",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "n_workers": 1,
        "full_information": false,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "scenario":"volunteers dilemma"
    },
    "88":{
        "note": "Pooled training - need to be ran with trainer_4v4. Betas in [0.2,0.4,0.6,0.8] are pooled and sampled from",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 600,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "n_workers": 1,
        "full_information": false,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "scenario":"volunteers dilemma"
    },
    "89":{
        "note": "Establishing baseline for coordination game with beta =0, and full information",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "n_workers": 1,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "90":{
        "note": "Establishing baseline for coordination game with beta =1, and full information",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 1,
        "n_workers": 1,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "91":{
        "note": "Baseline: Uniformly Mixed, beta =0",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"uniformly mixed"
    },
    "92":{
        "note": "Baseline: Uniformly mixed, with beta = 1",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1.0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"uniformly mixed"
    },
    "93":{
        "note": "Pooled training - need to be ran with trainer_4v4. Betas in [0.0,0.2,0.4,0.6,0.8,1.0] are pooled and sampled from",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "n_workers": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "scenario":"volunteers dilemma"
    },
    "94":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "95":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.80,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "96":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.60,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "97":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.40,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "98":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.20,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "99":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.00,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"coordination game"
    },
    "100":{
        "note": "Pooled training - need to be ran with trainer_4v4. Betas in [0.0,0.2,0.4,0.6,0.8,1.0] are pooled and sampled from",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "n_samples": 1,
        "n_workers": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "scenario":"coordination game"
    },
    "101":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "102":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.8,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "103":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.6,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "104":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.4,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "105":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.2,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "106":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": true,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "107":{
        "note": "Pooled, with all beta = 0.0",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "scenario":"volunteers dilemma"
    },
    "108":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "scenario":"volunteers dilemma"
    },
    "109":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "scenario":"volunteers dilemma"
    },
    "110":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "scenario":"coordination game"
    },
    "111":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "scenario":"coordination game"
    },
    "112":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "scenario":"coordination game"
    },
    "113":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"coordination game"
    },
    "114":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "115":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "116":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"volunteers dilemma"
    },
    "117":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "118":{
        "note": "Pooled, beta =0.3; experiments 112-118",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.3,
            "policy_1": 0.3,
            "policy_2": 0.3,
            "policy_3": 0.3,
            "policy_4": 0.3,
            "policy_5": 0.3
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "119":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"coordination game"
    },
    "120":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "121":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "122":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"volunteers dilemma"
    },
    "123":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "124":{
        "note": "Pooled, beta =0,0; experiments 119-124",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.0,
            "policy_2": 0.0,
            "policy_3": 0.0,
            "policy_4": 0.0,
            "policy_5": 0.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "125":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"coordination game"
    },
    "126":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "127":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "128":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"volunteers dilemma"
    },
    "129":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "130":{
        "note": "Pooled, beta =1; experiments 125-130",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 1.0,
            "policy_1": 1.0,
            "policy_2": 1.0,
            "policy_3": 1.0,
            "policy_4": 1.0,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "131":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"coordination game"
    },
    "132":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0

        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "133":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"coordination game"
    },
    "134":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": false,
        "scenario":"volunteers dilemma"
    },
    "135":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "136":{
        "note": "Pooled, with mixed betas",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": true,
        "policies":{
            "policy_0": 0.0,
            "policy_1": 0.2,
            "policy_2": 0.4,
            "policy_3": 0.6,
            "policy_4": 0.8,
            "policy_5": 1.0
        },
        "reveal_other_agents_identity": true,
        "reveal_other_agents_beta": true,
        "scenario":"volunteers dilemma"
    },
    "137":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":10,
        "scenario":"volunteers dilemma"
    },
    "138":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":15,
        "scenario":"volunteers dilemma"
    },
    "139":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":20,
        "scenario":"volunteers dilemma"
    },
    "140":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":10,
        "scenario":"coordination game"
    },
    "141":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":15,
        "scenario":"coordination game"
    },
    "142":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":20,
        "scenario":"coordination game"
    },
    "143":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":10,
        "scenario":"uniformly mixed"
    },
    "144":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":15,
        "scenario":"uniformly mixed"
    },
    "145":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 1.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "minimum_rescue_amount":3,
        "maximum_rescue_amount":20,
        "scenario":"uniformly mixed"
    },
    "146":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"uniformly mixed",
        "basic_model": true
    },
    "147":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"volunteers dilemma",
        "basic_model": true
    },
    "148":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"coordination game",
        "basic_model": true
    },
    "149":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"not in default",
        "basic_model": true
    },
    "150":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"only agent 0 can rescue",
        "basic_model": true
    },
    "151":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"only agent 1 can rescue",
        "basic_model": true
    },
    "152":{
        "note": "Experimenting with rescue amount ranges",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "pooled_training": false,
        "alpha": 1.0,
        "beta": 0.0,
        "reveal_other_agents_identity": false,
        "reveal_other_agents_beta": false,
        "scenario":"not enough money together",
        "basic_model": true
    },
    "153":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 1,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "154":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.8,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "155":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.6,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "156":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.4,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "157":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0.2,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "158":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 15,
        "invert_actions": false,
        "full_information": false,
        "pooled_training": false,
        "scenario":"volunteers dilemma"
    },
    "159":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "full_information": true,
        "scenario":"not enough money together"
    },
    "160":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "scenario":"not in default"
    },
    "161":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "scenario":"coordination game"
    },
    "162":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "scenario":"volunteers dilemma"
    },
    "163":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "scenario":"only agent 0 can rescue"
    },
    "164":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": true,
        "scenario":"only agent 1 can rescue"
    },
    "165":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "full_information": false,
        "scenario":"not enough money together"
    },
    "166":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"not in default"
    },
    "167":{
        "note": "Discrete, multi agent, multi graph",   
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"coordination game"
    },
    "168":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"volunteers dilemma"
    },
    "169":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"only agent 0 can rescue"
    },
    "170":{
        "note": "Discrete, multi agent, multi graph",
        "discrete": true,
        "run" : "DQN",
        "stop_iters": 200,
        "n_agents": 2,
        "number_of_negotiation_rounds": 1,
        "alpha": 1,
        "beta": 0,
        "debug": false,
        "n_samples": 1,
        "invert_actions": false,
        "full_information": false,
        "scenario":"only agent 1 can rescue"
    }
}
